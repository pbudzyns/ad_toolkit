{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6815e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9c649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# force torch to use CPU\n",
    "import torch\n",
    "# torch.cuda.empty_cache()\n",
    "torch.cuda.is_available = lambda : False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86dbb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sops_anomaly.datasets import KddCup, SupervisedDataset\n",
    "from sops_anomaly.detectors import AutoEncoder, VariationalAutoEncoder, LSTM_AD\n",
    "from sops_anomaly.evaluation import Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00676495",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_ROOT = pathlib.Path(\"../results/kdd_cup\")\n",
    "N_TRAIN_SAMPLES = 77000\n",
    "N_TEST_SAMPLES = 10000\n",
    "\n",
    "if not RESULTS_ROOT.exists():\n",
    "    RESULTS_ROOT.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac937804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_result(predictions, targets, max_error=None):\n",
    "    \"\"\"Try various threshold levels to get best scores.\"\"\"\n",
    "    best_f1 = -1\n",
    "    best_result = None\n",
    "    if max_error is None:\n",
    "        threshold_range = np.linspace(np.min(predictions), 3*np.mean(predictions), 100)\n",
    "    else:\n",
    "        threshold_range = np.linspace(0, max_error, 100)\n",
    "    for threshold in threshold_range:\n",
    "        labels = (predictions > threshold).astype(np.int32)\n",
    "        result = Result(labels, targets)\n",
    "        if result.f1 > best_f1:\n",
    "            best_f1 = result.f1\n",
    "            best_result = result\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f972fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(result, filename, root_folder=None):\n",
    "    \"\"\"Save tesults to csv file.\"\"\"\n",
    "    columns = ['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']\n",
    "    scores = [[result.accuracy, result.f1, result.precision, result.recall, result.roc_auc]]\n",
    "        \n",
    "    if root_folder is None:\n",
    "        file_path = RESULTS_ROOT / filename\n",
    "    else:\n",
    "        file_path = root_folder / filename\n",
    "\n",
    "    pd.DataFrame(data=scores, columns=columns).to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edec32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd = KddCup()\n",
    "kdd = SupervisedDataset(kdd)\n",
    "\n",
    "def get_dataset(anomaly_percentage=None):\n",
    "    \n",
    "    if anomaly_percentage is None:\n",
    "        train_data = kdd.get_train_samples(n_samples=N_TRAIN_SAMPLES)\n",
    "    else:\n",
    "        train_data = kdd.get_train_samples(n_samples=N_TRAIN_SAMPLES, anomaly_percentage=(anomaly_percentage/100))\n",
    "    test_data, test_targets = kdd.get_test_samples(n_samples=N_TEST_SAMPLES)\n",
    "    \n",
    "    return train_data, test_data, test_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00f06f0",
   "metadata": {},
   "source": [
    "## Auto-Encoder collect best results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7bce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for shape=(100, 50, 20), latent=20, train=77000, test=10000\n",
      "0.012025554664433002 0.32631135311294346 366.4491271972656\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.93,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.85,\n",
      "\ty_pred%=0.8609,\n",
      "\ty_label%=0.8031,\n",
      ")\n",
      "Testing for shape=(100, 50, 20), latent=10, train=77000, test=10000\n",
      "0.010279115289449692 0.27023307687211784 175.03125\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8553,\n",
      "\ty_label%=0.8019,\n",
      ")\n",
      "Testing for shape=(50,), latent=20, train=77000, test=10000\n",
      "0.00925627164542675 0.2517364828764461 198.85528564453125\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.93,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8565,\n",
      "\ty_label%=0.8017,\n",
      ")\n",
      "Testing for shape=(50,), latent=10, train=77000, test=10000\n",
      "0.019776316359639168 0.2493967878671363 199.3540496826172\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.93,\n",
      "\trecall=1.0,\n",
      "\tf1=0.96,\n",
      "\troc_auc=0.84,\n",
      "\ty_pred%=0.8609,\n",
      "\ty_label%=0.7977,\n",
      ")\n",
      "Testing for shape=(50, 20), latent=20, train=77000, test=10000\n",
      "0.018389437347650528 0.333014215349406 199.53329467773438\n",
      "Result(accuracy=0.93,\n",
      "\tprecision=0.92,\n",
      "\trecall=1.0,\n",
      "\tf1=0.96,\n",
      "\troc_auc=0.82,\n",
      "\ty_pred%=0.8712,\n",
      "\ty_label%=0.8,\n",
      ")\n",
      "Testing for shape=(50, 20), latent=10, train=77000, test=10000\n",
      "0.019969603046774864 0.3022963615119457 368.2611389160156\n",
      "Result(accuracy=0.93,\n",
      "\tprecision=0.92,\n",
      "\trecall=1.0,\n",
      "\tf1=0.96,\n",
      "\troc_auc=0.82,\n",
      "\ty_pred%=0.8749,\n",
      "\ty_label%=0.8043,\n",
      ")\n",
      "Testing for shape=(80, 40), latent=20, train=77000, test=10000\n",
      "0.010331341996788979 0.23711716125821694 77.02228546142578\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8515,\n",
      "\ty_label%=0.7981,\n",
      ")\n",
      "Testing for shape=(80, 40), latent=10, train=77000, test=10000\n",
      "0.010387425310909748 0.24865865001147613 192.8970184326172\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.93,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8562,\n",
      "\ty_label%=0.8006,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "shapes = ((100, 50, 20), (50, ), (50, 20, ), (80, 40,))\n",
    "# shapes = ((500, 300, 300,),)\n",
    "# latent_sizes = (10, 50, 100)\n",
    "latent_sizes = (20, 10)\n",
    "for shape in shapes:\n",
    "    for latent in latent_sizes:\n",
    "        train_data, test_data, test_targets = get_dataset()\n",
    "        print(f\"Testing for shape={shape}, latent={latent}, train={len(train_data)}, test={len(test_data)}\")\n",
    "\n",
    "        model = AutoEncoder(window_size=1, latent_size=latent, layers=shape)\n",
    "        model.train(train_data, epochs=30, verbose=False, learning_rate=1e-6)\n",
    "        predictions = model.predict(test_data)\n",
    "        result = best_result(predictions, test_targets)\n",
    "        print(np.min(predictions), np.mean(predictions), np.max(predictions))\n",
    "        print(result)\n",
    "\n",
    "\n",
    "        save_to_file(result, f\"autoencoder{'_'.join(str(x) for x in shape)}_{latent}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0af27f",
   "metadata": {},
   "source": [
    "## VariationalAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1be553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for shape=(100, 50, 20), latent=20, train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.93,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8585,\n",
      "\ty_label%=0.8023,\n",
      ")\n",
      "Testing for shape=(100, 50, 20), latent=10, train=77000, test=10000\n",
      "Result(accuracy=0.95,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8548,\n",
      "\ty_label%=0.8035,\n",
      ")\n",
      "Testing for shape=(50,), latent=20, train=77000, test=10000\n",
      "Result(accuracy=0.91,\n",
      "\tprecision=0.9,\n",
      "\trecall=1.0,\n",
      "\tf1=0.95,\n",
      "\troc_auc=0.77,\n",
      "\ty_pred%=0.8906,\n",
      "\ty_label%=0.8017,\n",
      ")\n",
      "Testing for shape=(50,), latent=10, train=77000, test=10000\n",
      "Result(accuracy=0.8,\n",
      "\tprecision=0.8,\n",
      "\trecall=1.0,\n",
      "\tf1=0.89,\n",
      "\troc_auc=0.5,\n",
      "\ty_pred%=0.9999,\n",
      "\ty_label%=0.8019,\n",
      ")\n",
      "Testing for shape=(50, 20), latent=20, train=77000, test=10000\n",
      "Result(accuracy=0.89,\n",
      "\tprecision=0.88,\n",
      "\trecall=1.0,\n",
      "\tf1=0.94,\n",
      "\troc_auc=0.74,\n",
      "\ty_pred%=0.9035,\n",
      "\ty_label%=0.7965,\n",
      ")\n",
      "Testing for shape=(50, 20), latent=10, train=77000, test=10000\n",
      "Result(accuracy=0.93,\n",
      "\tprecision=0.92,\n",
      "\trecall=1.0,\n",
      "\tf1=0.96,\n",
      "\troc_auc=0.82,\n",
      "\ty_pred%=0.8718,\n",
      "\ty_label%=0.8031,\n",
      ")\n",
      "Testing for shape=(80, 40), latent=20, train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=0.99,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8503,\n",
      "\ty_label%=0.8044,\n",
      ")\n",
      "Testing for shape=(80, 40), latent=10, train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=0.99,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8524,\n",
      "\ty_label%=0.8051,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "shapes = ((100, 50, 20), (50, ), (50, 20, ), (80, 40,))\n",
    "# shapes = ((500, 300, 300,),)\n",
    "# latent_sizes = (10, 50, 100)\n",
    "latent_sizes = (20, 10)\n",
    "for shape in shapes:\n",
    "    for latent in latent_sizes:\n",
    "        train_data, test_data, test_targets = get_dataset()\n",
    "        print(f\"Testing for shape={shape}, latent={latent}, train={len(train_data)}, test={len(test_data)}\")\n",
    "\n",
    "        model = VariationalAutoEncoder(window_size=1, latent_size=latent, layers=shape, l_samples=30)\n",
    "        model.train(train_data, epochs=30, verbose=False, learning_rate=1e-6)\n",
    "        predictions = model.predict(test_data)\n",
    "        result = best_result(predictions, test_targets)\n",
    "#         print(np.min(predictions), np.mean(predictions), np.max(predictions))\n",
    "        print(result)\n",
    "\n",
    "\n",
    "        save_to_file(result, f\"variationalautoencoder{'_'.join(str(x) for x in shape)}_{latent}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e4ffe",
   "metadata": {},
   "source": [
    "## Check impact of anomalous samples in trainign set for the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80878f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_ROOT = pathlib.Path(\"../results/kdd_cup\")\n",
    "N_TRAIN_SAMPLES = 77000\n",
    "N_TEST_SAMPLES = 10000\n",
    "\n",
    "if not RESULTS_ROOT.exists():\n",
    "    RESULTS_ROOT.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922c63c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 0%; train=77000, test=10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d97d9ebde1c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# TODO: insert best model ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# --------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sops_anomaly/sops_anomaly/detectors/autoencoder.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, epochs, batch_size, learning_rate, verbose)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch} loss: {epoch_loss/len(data_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sops_anomaly/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sops_anomaly/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sops_anomaly/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sops_anomaly/lib/python3.6/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# AutoEncoder\n",
    "for percent in (0, 1, 3, 5, 10, 15, 20):\n",
    "    result_folder = RESULTS_ROOT / f\"{percent}percent\"\n",
    "    if not result_folder.exists():\n",
    "        result_folder.mkdir()\n",
    "    \n",
    "    train_data, test_data, test_targets = get_dataset(percent)\n",
    "    print(f\"Testing for {percent}%; train={len(train_data)}, test={len(test_data)}\")\n",
    "    \n",
    "    # TODO: insert best model ----------------------------\n",
    "    model = AutoEncoder(window_size=1, latent_size=20, layers=(50,))\n",
    "    model.train(train_data, epochs=30, verbose=False, learning_rate=1e-6)\n",
    "    # --------------------------------\n",
    "\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    result = best_result(predictions, test_targets)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    save_to_file(result, \"autoencoder\", root_folder=result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4dd7d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 0%; train=77000, test=10000\n",
      "Result(accuracy=0.95,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.87,\n",
      "\ty_pred%=0.8544,\n",
      "\ty_label%=0.8021,\n",
      ")\n",
      "Testing for 1%; train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.93,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.853,\n",
      "\ty_label%=0.7982,\n",
      ")\n",
      "Testing for 3%; train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8494,\n",
      "\ty_label%=0.7999,\n",
      ")\n",
      "Testing for 5%; train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=0.99,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.87,\n",
      "\ty_pred%=0.8485,\n",
      "\ty_label%=0.8007,\n",
      ")\n",
      "Testing for 10%; train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8525,\n",
      "\ty_label%=0.7985,\n",
      ")\n",
      "Testing for 15%; train=77000, test=10000\n",
      "Result(accuracy=0.94,\n",
      "\tprecision=0.94,\n",
      "\trecall=1.0,\n",
      "\tf1=0.97,\n",
      "\troc_auc=0.86,\n",
      "\ty_pred%=0.8542,\n",
      "\ty_label%=0.8026,\n",
      ")\n",
      "Testing for 20%; train=77000, test=10000\n",
      "Result(accuracy=0.93,\n",
      "\tprecision=0.92,\n",
      "\trecall=1.0,\n",
      "\tf1=0.96,\n",
      "\troc_auc=0.82,\n",
      "\ty_pred%=0.874,\n",
      "\ty_label%=0.8026,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VariationalAutoEncoder\n",
    "for percent in (0, 1, 3, 5, 10, 15, 20):\n",
    "    result_folder = RESULTS_ROOT / f\"{percent}percent\"\n",
    "    if not result_folder.exists():\n",
    "        result_folder.mkdir()\n",
    "    \n",
    "    train_data, test_data, test_targets = get_dataset(percent)\n",
    "    print(f\"Testing for {percent}%; train={len(train_data)}, test={len(test_data)}\")\n",
    "    # TODO: insert best model ----------------------------\n",
    "    model = VariationalAutoEncoder(window_size=1, latent_size=10, layers=(80, 40), l_samples=30)\n",
    "    model.train(train_data, epochs=30, verbose=False, learning_rate=1e-6)\n",
    "    # --------------------------------\n",
    "\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    result = best_result(predictions, test_targets)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    save_to_file(result, \"variationalautoencoder\", root_folder=result_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
