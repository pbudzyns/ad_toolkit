# import torch
#
# # To ensure using CPU during testing, avoids CUDA Device Memory Full error
# torch.cuda.is_available = lambda: True
